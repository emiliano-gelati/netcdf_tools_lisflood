{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of NetCDF slicing with xarray\n",
    "The package \"xarray\" provides a high level interface to NetCDF files. For CDO-like operations on large datasets that do not fit in memory, the package \"dask\" is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask # check if dask is installed (not used directly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we use the 1990-2014 precipitation file used to force LISFLOOD over Europe (approximately 30 GB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/net/ies-mpd01/vol/H01_Fresh_Water/Europe/forcing_data/JRC_5km_meteo_forcing_netcdf/chunking_20x20x20_uncompressed/pr.nc'\n",
    "nc = xr.open_dataset(path, chunks={'time': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a file is open using the \"chunks\" keyword argument, operations can be declared on datasets that do not fit in memory relying on dask lazy evaluation (http://xarray.pydata.org/en/stable/dask.html#). The specified chunks must fit in the computer's memory.\n",
    "\n",
    "To see the data variable's shape and dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9131, 950, 1000)\n",
      "(u'time', u'y', u'x')\n"
     ]
    }
   ],
   "source": [
    "print nc.pr.shape\n",
    "print nc.pr.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the slicing masks along the \"x\" and \"y\" dimensions, given some lower and upper bounds (for indexing methods, see: http://xarray.pydata.org/en/stable/indexing.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_y = xr.ufuncs.logical_and(nc.y >= 2992500, nc.y <= 2997500)\n",
    "mask_x = xr.ufuncs.logical_and(nc.x >= 5002500, nc.x <= 5007500)\n",
    "sliced_pr = nc.pr[:,mask_y,mask_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slicing is actually performed when the declared sliced variable (sliced_pr) is written to a NetCDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slicing took 257.65 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = pd.datetime.now()\n",
    "sliced_pr.to_netcdf('sliced_pr.nc') # the actual computing is performed here\n",
    "print 'The slicing took {:.2f} seconds'.format((pd.datetime.now() - t0).total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newly created NetCDF file contains only 1 data variable (pr) with its attributes and dimensions. The missing variable (lambert_azimuthal_equal_area) and global file attributes can be copied from the source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nc = xr.open_dataset('sliced_pr.nc')\n",
    "new_nc['lambert_azimuthal_equal_area'] = nc['lambert_azimuthal_equal_area']\n",
    "new_nc.attrs = nc.attrs\n",
    "new_nc.to_netcdf('sliced_pr_with_metadata.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other operations can be declared on large datasets and evaluated lazily using xarray+dask, e.g.:\n",
    "* group-by: http://xarray.pydata.org/en/stable/groupby.html\n",
    "* resample: http://xarray.pydata.org/en/stable/generated/xarray.DataArray.resample.html?highlight=resample\n",
    "\n",
    "A lower-level interface to NetCDF files is provided by the netCDF4 package (http://unidata.github.io/netcdf4-python/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
